{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd095bb600096007ab9f567dd294a4f24ed256a7f8cd3baa781798d9a0497e2540f",
   "display_name": "Python 3.8.5 64-bit ('scraping-clacso': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import html\n",
    "import scrapy\n",
    "from time import sleep\n",
    "import urllib3\n",
    "import json\n",
    "from selenium import webdriver\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(link):\n",
    "\n",
    "    encabezados = {\n",
    "    'user-agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36'\n",
    "    }\n",
    "\n",
    "    resp = requests.get(link, headers=encabezados, verify=False)\n",
    "    resp = resp.text\n",
    "\n",
    "    #soup = get_Soup('https://minciencias.gov.co/convocatorias/todas')\n",
    "    parser = html.fromstring(resp)\n",
    "    urllib3.disable_warnings()\n",
    "\n",
    "    return parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/duban/anaconda3/envs/scraping-clacso/lib/python3.8/site-packages/urllib3/connectionpool.py:981: InsecureRequestWarning: Unverified HTTPS request is being made to host 'www.fapeal.br'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "fapeal = pd.DataFrame()\n",
    "\n",
    "links_proyectos = []\n",
    "fechas_proyectos = []\n",
    "titulos_proyectos = []\n",
    "pdfs_proyectos = []\n",
    "\n",
    "estados = [\"https://www.fapeal.br/category/editais/editais-vigentes/\", \"https://www.fapeal.br/category/editais/editais-encerrados/\", \"https://www.fapeal.br/category/editais/chamadas-abertas/\"]\n",
    "\n",
    "\n",
    "for estado in estados:\n",
    "\n",
    "\n",
    "\n",
    "    #paginaciá¹•m\n",
    "    parser_estado = parser(estado)\n",
    "    paginacion = parser_estado.xpath('//div[@class=\"nav-links\"]//text()')\n",
    "    pag = []\n",
    "    for i in paginacion:\n",
    "        if i.isdigit():\n",
    "            pag.append(i)\n",
    "    \n",
    "    pag_max = sorted(pag, reverse=True)[0]\n",
    "\n",
    "    n = 1\n",
    "    while n <= int(pag_max):\n",
    "\n",
    "        end = \"page/\"+ str(n) +\"/\"\n",
    "\n",
    "        if n == 1:\n",
    "            parser_proyectos = parser(estado)\n",
    "        else:\n",
    "            parser_proyectos = parser(estado+end)\n",
    "\n",
    "        titulos = []\n",
    "        fechas = []\n",
    "        links = []\n",
    "\n",
    "        #link\n",
    "        links = sorted(list(set(parser_proyectos.xpath('//div[@class=\"list-left-wrap\"]//a/@href'))),reverse=True)\n",
    "\n",
    "        #Titulos\n",
    "        tits = parser_proyectos.xpath('//div[@class=\"list-left-wrap\"]//h2[@class=\"entry-title\"]/a/text()')\n",
    "        for tit in tits:\n",
    "            titulos.append(tit.strip())\n",
    "\n",
    "        #Fechas\n",
    "        fechas = parser_proyectos.xpath('//div[@class=\"list-left-wrap\"]//div[@class=\"entry-meta\"]/span/text()')\n",
    "\n",
    "        for fecha in fechas:\n",
    "            if fecha.isdigit():\n",
    "                fechas.remove(fecha)\n",
    "        \n",
    "        n+=1\n",
    "\n",
    "        links_proyectos+=links\n",
    "        fechas_proyectos+=fechas\n",
    "        titulos_proyectos+=titulos\n",
    "\n",
    "# pdfs\n",
    "for link in links_proyectos:\n",
    "\n",
    "    parser_proyecto = parser(link)\n",
    "\n",
    "    pdfs_proyecto = ''\n",
    "\n",
    "    pdfs = parser_proyecto.xpath('//a/@href')\n",
    "\n",
    "    for pdf in pdfs:\n",
    "        if pdf.endswith('.pdf') or pdf.startswith('http://resultado.cnpq.br/'):\n",
    "            pdfs_proyecto = pdfs_proyecto + pdf + ', '\n",
    "\n",
    "    pdfs_proyectos.append(pdfs_proyecto.strip(', '))\n",
    "\n",
    "fapeal['Titulo'] = titulos_proyectos\n",
    "fapeal['Fecha'] = fechas_proyectos\n",
    "fapeal['link'] = links_proyectos\n",
    "fapeal['pdfs'] = pdfs_proyectos\n",
    "\n",
    "#fapeal.to_excel('brasil_Fapeal.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fapeal.to_excel('brasil_Fapeal.xlsx')"
   ]
  }
 ]
}